#!/usr/bin/env python3
"""
Script de Validation Pre-D√©ploiement After Effects
V√©rifie que tout est pr√™t avant le d√©ploiement des s√©quences
"""

import sys
import os
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple

# Ajouter le g√©n√©rateur au path
sys.path.append(str(Path(__file__).parent))

from generate_ae_projects_v2 import AfterEffectsGeneratorV2

class PreDeploymentValidator:
    """Validateur pr√©-d√©ploiement pour After Effects."""
    
    def __init__(self):
        self.generator = AfterEffectsGeneratorV2()
        self.test_sequences = ["SQ01", "SQ02", "SQ03"]
        
    def validate_environment(self) -> bool:
        """Valide l'environnement de d√©ploiement."""
        print("üîç VALIDATION ENVIRONNEMENT")
        print("=" * 40)
        
        checks = []
        
        # 1. V√©rifier chemins sources
        sequences_path = Path("/Volumes/resizelab/o2b-undllm/3_PROJECTS/2_ANIM/SEQUENCES")
        edit_path = Path("/Volumes/resizelab/o2b-undllm/2_IN/_FROM_EDIT/BY_SHOTS")
        grading_path = Path("/Volumes/resizelab/o2b-undllm/2_IN/_FROM_GRADING/BY_SHOTS")
        config_path = Path(__file__).parent.parent.parent / "config" / "after_effects_mapping_gsheets.json"
        
        print("üìÅ V√©rification des chemins...")
        
        if sequences_path.exists():
            print(f"   ‚úÖ Dossier s√©quences : {sequences_path}")
            checks.append(True)
        else:
            print(f"   ‚ùå Dossier s√©quences manquant : {sequences_path}")
            checks.append(False)
        
        if edit_path.exists():
            edit_files = list(edit_path.glob("UNDLM_*.mov"))
            print(f"   ‚úÖ Dossier EDIT : {len(edit_files)} fichiers .mov")
            checks.append(True)
        else:
            print(f"   ‚ùå Dossier EDIT manquant : {edit_path}")
            checks.append(False)
        
        if grading_path.exists():
            graded_files = list(grading_path.glob("UNDLM_*.mov"))
            print(f"   ‚úÖ Dossier GRADING : {len(graded_files)} fichiers .mov")
            checks.append(True)
        else:
            print(f"   ‚ùå Dossier GRADING manquant : {grading_path}")
            checks.append(False)
        
        if config_path.exists():
            print(f"   ‚úÖ Configuration : {config_path}")
            checks.append(True)
        else:
            print(f"   ‚ùå Configuration manquante : {config_path}")
            checks.append(False)
        
        # 2. V√©rifier droits d'√©criture
        print("\nüîê V√©rification des droits...")
        
        try:
            test_dir = sequences_path / "_TEST_WRITE"
            test_dir.mkdir(exist_ok=True)
            test_file = test_dir / "test.txt"
            test_file.write_text("test")
            test_file.unlink()
            test_dir.rmdir()
            print("   ‚úÖ Droits d'√©criture OK")
            checks.append(True)
        except Exception as e:
            print(f"   ‚ùå Pas de droits d'√©criture : {e}")
            checks.append(False)
        
        success_rate = sum(checks) / len(checks) * 100
        print(f"\nüìä Environnement : {success_rate:.1f}% OK ({sum(checks)}/{len(checks)})")
        
        return all(checks)
    
    def validate_data_integrity(self) -> bool:
        """Valide l'int√©grit√© des donn√©es."""
        print("\nüìä VALIDATION DONN√âES")
        print("=" * 40)
        
        try:
            # Charger les donn√©es
            sequence_data = self.generator.load_sequence_data()
            
            total_sequences = len(sequence_data)
            total_plans = sum(len(seq['plans']) for seq in sequence_data.values())
            
            print(f"üìã Donn√©es charg√©es :")
            print(f"   ‚Ä¢ S√©quences : {total_sequences}")
            print(f"   ‚Ä¢ Plans total : {total_plans}")
            
            # V√©rifier coh√©rence des donn√©es
            print(f"\nüîç V√©rification coh√©rence...")
            
            issues = []
            
            for seq_id, seq_info in sequence_data.items():
                plans = seq_info['plans']
                
                # V√©rifier structure s√©quence
                if not seq_info.get('name'):
                    issues.append(f"{seq_id}: nom manquant")
                
                if not plans:
                    issues.append(f"{seq_id}: aucun plan")
                
                # V√©rifier plans
                for plan in plans:
                    if not plan.get('plan_num'):
                        issues.append(f"{seq_id}: plan sans num√©ro")
                    
                    if not plan.get('duration') or plan['duration'] <= 0:
                        issues.append(f"{seq_id}: plan {plan.get('plan_num', '?')} dur√©e invalide")
            
            if issues:
                print(f"   ‚ö†Ô∏è  {len(issues)} probl√®mes d√©tect√©s :")
                for issue in issues[:5]:  # Afficher max 5
                    print(f"      ‚Ä¢ {issue}")
                if len(issues) > 5:
                    print(f"      ... et {len(issues) - 5} autres")
                return False
            else:
                print(f"   ‚úÖ Donn√©es coh√©rentes")
                return True
                
        except Exception as e:
            print(f"   ‚ùå Erreur validation donn√©es : {e}")
            return False
    
    def validate_source_files(self) -> Tuple[bool, Dict]:
        """Valide la disponibilit√© des fichiers sources."""
        print(f"\nüìπ VALIDATION FICHIERS SOURCES")
        print("=" * 40)
        
        try:
            sequence_data = self.generator.load_sequence_data()
            
            # Analyser quelques s√©quences test
            test_results = {}
            
            for seq_id in self.test_sequences:
                if seq_id not in sequence_data:
                    continue
                    
                print(f"\nüé¨ Analyse {seq_id}...")
                plans = sequence_data[seq_id]['plans']
                
                # V√©rifier fichiers EDIT
                edit_available = []
                graded_available = []
                
                for plan in plans:
                    plan_num = plan['plan_num']
                    
                    # Fichier EDIT
                    edit_file = Path(f"/Volumes/resizelab/o2b-undllm/2_IN/_FROM_EDIT/BY_SHOTS/UNDLM_{plan_num:05d}.mov")
                    if edit_file.exists():
                        edit_available.append(plan_num)
                    
                    # Fichier GRADED
                    graded_file = Path(f"/Volumes/resizelab/o2b-undllm/2_IN/_FROM_GRADING/BY_SHOTS/UNDLM_{plan_num:05d}.mov")
                    if graded_file.exists():
                        graded_available.append(plan_num)
                
                edit_rate = len(edit_available) / len(plans) * 100
                graded_rate = len(graded_available) / len(plans) * 100
                
                print(f"   üìÑ Plans EDIT : {len(edit_available)}/{len(plans)} ({edit_rate:.1f}%)")
                print(f"   üé® Plans GRADED : {len(graded_available)}/{len(plans)} ({graded_rate:.1f}%)")
                
                test_results[seq_id] = {
                    'total_plans': len(plans),
                    'edit_available': len(edit_available),
                    'graded_available': len(graded_available),
                    'edit_rate': edit_rate,
                    'graded_rate': graded_rate
                }
            
            # R√©sultats globaux
            print(f"\nüìä R√âSUM√â FICHIERS SOURCES :")
            for seq_id, results in test_results.items():
                print(f"   {seq_id}: EDIT {results['edit_rate']:.0f}% | GRADED {results['graded_rate']:.0f}%")
            
            # Consid√©rer comme OK si au moins 80% des fichiers EDIT sont pr√©sents
            min_edit_rate = min(r['edit_rate'] for r in test_results.values()) if test_results else 0
            
            if min_edit_rate >= 80:
                print(f"   ‚úÖ Fichiers sources OK (minimum {min_edit_rate:.0f}%)")
                return True, test_results
            else:
                print(f"   ‚ö†Ô∏è  Fichiers sources insuffisants (minimum {min_edit_rate:.0f}%)")
                return False, test_results
                
        except Exception as e:
            print(f"   ‚ùå Erreur validation fichiers : {e}")
            return False, {}
    
    def run_dry_run_test(self) -> bool:
        """Ex√©cute un test dry-run sur SQ02."""
        print(f"\nüß™ TEST DRY-RUN SQ02")
        print("=" * 40)
        
        try:
            print("üöÄ G√©n√©ration test SQ02 (simulation)...")
            success = self.generator.generate_for_sequence("SQ02", dry_run=True)
            
            if success:
                print("   ‚úÖ Test dry-run r√©ussi")
                
                # V√©rifier que le script aurait √©t√© g√©n√©r√©
                script_path = Path("/Volumes/resizelab/o2b-undllm/3_PROJECTS/2_ANIM/SEQUENCES/SQ02/_AE/SQ02_generation_script_v2.jsx")
                if script_path.exists():
                    script_size = script_path.stat().st_size
                    print(f"   ‚úÖ Script g√©n√©r√© : {script_size} bytes")
                else:
                    print("   ‚ö†Ô∏è  Script non trouv√© (normal en dry-run)")
                
                return True
            else:
                print("   ‚ùå Test dry-run √©chou√©")
                return False
                
        except Exception as e:
            print(f"   ‚ùå Erreur test dry-run : {e}")
            return False
    
    def generate_validation_report(self) -> Dict:
        """G√©n√®re un rapport de validation complet."""
        print(f"\nüìã G√âN√âRATION RAPPORT VALIDATION")
        print("=" * 40)
        
        # Ex√©cuter toutes les validations
        env_ok = self.validate_environment()
        data_ok = self.validate_data_integrity()
        sources_ok, sources_details = self.validate_source_files()
        dryrun_ok = self.run_dry_run_test()
        
        # Calculer score global
        checks = [env_ok, data_ok, sources_ok, dryrun_ok]
        global_score = sum(checks) / len(checks) * 100
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'environment': env_ok,
            'data_integrity': data_ok,
            'source_files': sources_ok,
            'dry_run_test': dryrun_ok,
            'global_score': global_score,
            'ready_for_deployment': global_score >= 75,
            'source_files_details': sources_details
        }
        
        # Afficher r√©sultats
        print(f"\nüéØ RAPPORT FINAL :")
        print(f"   üåê Environnement : {'‚úÖ' if env_ok else '‚ùå'}")
        print(f"   üìä Donn√©es : {'‚úÖ' if data_ok else '‚ùå'}")
        print(f"   üìπ Fichiers sources : {'‚úÖ' if sources_ok else '‚ùå'}")
        print(f"   üß™ Test dry-run : {'‚úÖ' if dryrun_ok else '‚ùå'}")
        print(f"   üìà Score global : {global_score:.1f}%")
        
        if report['ready_for_deployment']:
            print(f"\nüöÄ ‚úÖ PR√äT POUR D√âPLOIEMENT !")
        else:
            print(f"\n‚ö†Ô∏è  ‚ùå PAS PR√äT - Corriger les probl√®mes d'abord")
        
        # Sauvegarder rapport
        reports_dir = Path(__file__).parent / "validation_reports"
        reports_dir.mkdir(exist_ok=True)
        report_file = reports_dir / f"pre_deployment_validation_{time.strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ Rapport sauvegard√© : {report_file}")
        
        return report

def main():
    """Fonction principale."""
    import time
    
    print("üîç VALIDATION PR√â-D√âPLOIEMENT AFTER EFFECTS")
    print("=" * 60)
    print(f"üìÖ {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    validator = PreDeploymentValidator()
    report = validator.generate_validation_report()
    
    return 0 if report['ready_for_deployment'] else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
