#!/usr/bin/env python3
"""
Script principal d'int√©gration LucidLink ‚Üí Frame.io
Connecte le watcher LucidLink existant avec la nouvelle int√©gration Frame.io
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging
import json
from datetime import datetime

# Ajouter le chemin source au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.integrations.frameio.integration import FrameIOIntegrationManager, create_frameio_integration

# Configuration du logging
logger = logging.getLogger(__name__)

class LucidLinkFrameIOBridge:
    """
    Pont entre LucidLink et Frame.io
    √âcoute les √©v√©nements du watcher LucidLink et d√©clenche les uploads Frame.io
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialise le pont LucidLink ‚Üí Frame.io
        
        Args:
            config: Configuration compl√®te du pipeline
        """
        self.config = config
        self.running = False
        self.processed_files = set()
        self.stats = {
            'files_detected': 0,
            'files_processed': 0,
            'files_uploaded': 0,
            'files_failed': 0,
            'start_time': None
        }
        
        # Initialiser l'int√©gration Frame.io
        self.frameio_integration = create_frameio_integration(config)
        
        # Configuration du watcher
        self.watch_path = config.get('lucidlink', {}).get('by_shot_path', '/path/to/BY_SHOT')
        self.file_extensions = config.get('lucidlink', {}).get('supported_extensions', 
                                                            ['.mov', '.mp4', '.avi', '.mkv', '.prores'])
        self.min_file_size = config.get('lucidlink', {}).get('min_file_size', 1024 * 1024)  # 1MB
        self.processing_delay = config.get('lucidlink', {}).get('processing_delay', 10)  # 10 secondes
        
        # √âtat des fichiers en cours de traitement
        self.processing_queue = asyncio.Queue()
        self.processing_tasks = []
        
        logger.info(f"‚úÖ Pont LucidLink ‚Üí Frame.io initialis√©")
        logger.info(f"üìÅ Surveillance: {self.watch_path}")
        logger.info(f"üìù Extensions: {self.file_extensions}")
    
    async def start_bridge(self):
        """D√©marre le pont d'int√©gration"""
        try:
            self.running = True
            self.stats['start_time'] = datetime.now()
            
            logger.info("üöÄ D√©marrage du pont LucidLink ‚Üí Frame.io")
            
            # D√©marrer les workers de traitement
            await self._start_processing_workers()
            
            # D√©marrer la surveillance des fichiers
            await self._start_file_watcher()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage pont: {e}")
            await self.stop_bridge()
    
    async def stop_bridge(self):
        """Arr√™te le pont d'int√©gration"""
        try:
            logger.info("üõë Arr√™t du pont LucidLink ‚Üí Frame.io")
            self.running = False
            
            # Arr√™ter les workers
            for task in self.processing_tasks:
                task.cancel()
            
            # Attendre la fin des t√¢ches en cours
            if self.processing_tasks:
                await asyncio.gather(*self.processing_tasks, return_exceptions=True)
            
            # Afficher les statistiques finales
            self._log_final_stats()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur arr√™t pont: {e}")
    
    async def _start_processing_workers(self):
        """D√©marre les workers de traitement des fichiers"""
        try:
            max_workers = self.config.get('frameio', {}).get('max_concurrent_uploads', 3)
            
            for i in range(max_workers):
                task = asyncio.create_task(self._processing_worker(f"Worker-{i+1}"))
                self.processing_tasks.append(task)
            
            logger.info(f"‚úÖ {max_workers} workers de traitement d√©marr√©s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage workers: {e}")
    
    async def _processing_worker(self, worker_name: str):
        """Worker qui traite les fichiers de la queue"""
        try:
            logger.info(f"üîÑ {worker_name} d√©marr√©")
            
            while self.running:
                try:
                    # R√©cup√©rer un fichier de la queue (timeout 1 seconde)
                    file_path = await asyncio.wait_for(
                        self.processing_queue.get(), 
                        timeout=1.0
                    )
                    
                    # Traiter le fichier
                    await self._process_file(file_path, worker_name)
                    
                    # Marquer la t√¢che comme termin√©e
                    self.processing_queue.task_done()
                    
                except asyncio.TimeoutError:
                    # Pas de fichier dans la queue, continuer
                    continue
                except Exception as e:
                    logger.error(f"‚ùå Erreur dans {worker_name}: {e}")
                    
        except asyncio.CancelledError:
            logger.info(f"üõë {worker_name} arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur worker {worker_name}: {e}")
    
    async def _start_file_watcher(self):
        """D√©marre la surveillance des fichiers"""
        try:
            # Impl√©mentation simplifi√©e du watcher
            # Dans un vrai d√©ploiement, on utiliserait watchdog ou inotify
            
            logger.info(f"üëÄ Surveillance d√©marr√©e: {self.watch_path}")
            
            while self.running:
                try:
                    # Scanner le dossier BY_SHOT
                    await self._scan_for_new_files()
                    
                    # Attendre avant le prochain scan
                    await asyncio.sleep(5)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur surveillance: {e}")
                    await asyncio.sleep(10)
                    
        except asyncio.CancelledError:
            logger.info("üõë Surveillance arr√™t√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur surveillance: {e}")
    
    async def _scan_for_new_files(self):
        """Scanne le dossier BY_SHOT pour de nouveaux fichiers"""
        try:
            watch_path = Path(self.watch_path)
            
            if not watch_path.exists():
                logger.warning(f"‚ö†Ô∏è Dossier BY_SHOT introuvable: {self.watch_path}")
                return
            
            # Chercher les fichiers vid√©o
            for file_path in watch_path.rglob('*'):
                if (file_path.is_file() and 
                    file_path.suffix.lower() in self.file_extensions and
                    str(file_path) not in self.processed_files):
                    
                    # V√©rifier la taille du fichier
                    if file_path.stat().st_size < self.min_file_size:
                        continue
                    
                    # Attendre que le fichier soit stable (pas en cours d'√©criture)
                    if not await self._is_file_stable(file_path):
                        continue
                    
                    # Ajouter √† la queue de traitement
                    await self.processing_queue.put(str(file_path))
                    self.processed_files.add(str(file_path))
                    self.stats['files_detected'] += 1
                    
                    logger.info(f"üìÑ Nouveau fichier d√©tect√©: {file_path.name}")
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur scan fichiers: {e}")
    
    async def _is_file_stable(self, file_path: Path) -> bool:
        """V√©rifie qu'un fichier n'est plus en cours d'√©criture"""
        try:
            # Prendre la taille du fichier
            size1 = file_path.stat().st_size
            
            # Attendre un peu
            await asyncio.sleep(2)
            
            # Reprendre la taille
            size2 = file_path.stat().st_size
            
            # Si les tailles sont identiques, le fichier est stable
            return size1 == size2
            
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification stabilit√© {file_path}: {e}")
            return False
    
    async def _process_file(self, file_path: str, worker_name: str):
        """Traite un fichier sp√©cifique"""
        try:
            logger.info(f"üîÑ {worker_name} traite: {Path(file_path).name}")
            self.stats['files_processed'] += 1
            
            # Utiliser l'int√©gration Frame.io pour traiter le fichier
            result = await self.frameio_integration.process_file(file_path)
            
            if result['status'] == 'success':
                self.stats['files_uploaded'] += 1
                logger.info(f"‚úÖ {worker_name} - Upload r√©ussi: {result['metadata']['nomenclature']}")
                
                # Optionnel : d√©placer le fichier vers un dossier "processed"
                await self._move_to_processed(file_path)
                
            else:
                self.stats['files_failed'] += 1
                logger.error(f"‚ùå {worker_name} - √âchec upload: {result['error']}")
                
                # Optionnel : d√©placer vers un dossier "failed"
                await self._move_to_failed(file_path, result['error'])
                
        except Exception as e:
            self.stats['files_failed'] += 1
            logger.error(f"‚ùå {worker_name} - Erreur traitement {file_path}: {e}")
    
    async def _move_to_processed(self, file_path: str):
        """D√©place un fichier vers le dossier processed (optionnel)"""
        try:
            if not self.config.get('lucidlink', {}).get('move_processed_files', False):
                return
            
            source_path = Path(file_path)
            processed_dir = source_path.parent / "processed"
            processed_dir.mkdir(exist_ok=True)
            
            target_path = processed_dir / source_path.name
            source_path.rename(target_path)
            
            logger.info(f"üìÅ Fichier d√©plac√© vers processed: {source_path.name}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©placement processed: {e}")
    
    async def _move_to_failed(self, file_path: str, error: str):
        """D√©place un fichier vers le dossier failed (optionnel)"""
        try:
            if not self.config.get('lucidlink', {}).get('move_failed_files', False):
                return
            
            source_path = Path(file_path)
            failed_dir = source_path.parent / "failed"
            failed_dir.mkdir(exist_ok=True)
            
            target_path = failed_dir / source_path.name
            source_path.rename(target_path)
            
            # Cr√©er un fichier d'erreur
            error_file = failed_dir / f"{source_path.stem}.error"
            with open(error_file, 'w') as f:
                f.write(f"Error: {error}\nTimestamp: {datetime.now().isoformat()}")
            
            logger.info(f"üìÅ Fichier d√©plac√© vers failed: {source_path.name}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©placement failed: {e}")
    
    def _log_final_stats(self):
        """Affiche les statistiques finales"""
        try:
            if self.stats['start_time']:
                duration = datetime.now() - self.stats['start_time']
                logger.info(f"üìä Statistiques finales (dur√©e: {duration}):")
                logger.info(f"  üìÑ Fichiers d√©tect√©s: {self.stats['files_detected']}")
                logger.info(f"  üîÑ Fichiers trait√©s: {self.stats['files_processed']}")
                logger.info(f"  ‚úÖ Fichiers upload√©s: {self.stats['files_uploaded']}")
                logger.info(f"  ‚ùå Fichiers √©chou√©s: {self.stats['files_failed']}")
                
                if self.stats['files_processed'] > 0:
                    success_rate = (self.stats['files_uploaded'] / self.stats['files_processed']) * 100
                    logger.info(f"  üìà Taux de r√©ussite: {success_rate:.1f}%")
        except Exception as e:
            logger.error(f"‚ùå Erreur statistiques: {e}")
    
    async def get_status(self) -> Dict[str, Any]:
        """Retourne le statut actuel du pont"""
        return {
            'running': self.running,
            'stats': self.stats,
            'queue_size': self.processing_queue.qsize(),
            'processed_files_count': len(self.processed_files),
            'frameio_integration_status': await self.frameio_integration.get_processing_status()
        }

async def load_configuration() -> Dict[str, Any]:
    """Charge la configuration depuis les fichiers et variables d'environnement"""
    try:
        # Configuration de base
        config = {
            'frameio': {
                'account_id': os.getenv('FRAMEIO_ACCOUNT_ID'),
                'workspace_id': os.getenv('FRAMEIO_WORKSPACE_ID'),
                'project_id': os.getenv('FRAMEIO_PROJECT_ID'),
                'base_url': os.getenv('FRAMEIO_BASE_URL', 'https://api.frame.io/v4'),
                'max_concurrent_uploads': int(os.getenv('MAX_CONCURRENT_UPLOADS', '3')),
                'oauth': {
                    'client_id': os.getenv('FRAMEIO_CLIENT_ID'),
                    'client_secret': os.getenv('FRAMEIO_CLIENT_SECRET'),
                    'jwt_key': os.getenv('FRAMEIO_JWT_KEY'),
                    'token_url': os.getenv('FRAMEIO_TOKEN_URL', 'https://auth.frame.io/oauth2/token')
                }
            },
            'discord': {
                'webhook_url': os.getenv('DISCORD_WEBHOOK_URL')
            },
            'lucidlink': {
                'by_shot_path': os.getenv('LUCIDLINK_BY_SHOT_PATH', '/path/to/BY_SHOT'),
                'supported_extensions': ['.mov', '.mp4', '.avi', '.mkv', '.prores', '.mxf'],
                'min_file_size': int(os.getenv('MIN_FILE_SIZE', '1048576')),  # 1MB
                'processing_delay': int(os.getenv('PROCESSING_DELAY', '10')),
                'move_processed_files': os.getenv('MOVE_PROCESSED_FILES', 'false').lower() == 'true',
                'move_failed_files': os.getenv('MOVE_FAILED_FILES', 'false').lower() == 'true'
            },
            'logging': {
                'level': os.getenv('LOG_LEVEL', 'INFO'),
                'file': os.getenv('LOG_FILE', 'logs/frameio_integration.log'),
                'max_size': int(os.getenv('LOG_MAX_SIZE', '10485760')),  # 10MB
                'backup_count': int(os.getenv('LOG_BACKUP_COUNT', '5'))
            }
        }
        
        # Charger la configuration depuis un fichier JSON si pr√©sent
        config_file = os.getenv('CONFIG_FILE', 'config/frameio_integration.json')
        if Path(config_file).exists():
            with open(config_file, 'r') as f:
                file_config = json.load(f)
                # Fusionner les configurations (fichier prioritaire)
                config = {**config, **file_config}
        
        return config
        
    except Exception as e:
        logger.error(f"‚ùå Erreur chargement configuration: {e}")
        raise

async def main():
    """Fonction principale du pont d'int√©gration"""
    try:
        print("üé¨ D√©marrage du pont LucidLink ‚Üí Frame.io")
        print("=" * 50)
        
        # Charger la configuration
        config = await load_configuration()
        
        # Configurer le logging basique
        logging_config = config.get('logging', {})
        log_level = getattr(logging, logging_config.get('level', 'INFO').upper())
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(logging_config.get('file', 'logs/frameio_integration.log')),
                logging.StreamHandler()
            ]
        )
        
        # V√©rifier la configuration
        required_vars = ['FRAMEIO_ACCOUNT_ID', 'FRAMEIO_WORKSPACE_ID', 'FRAMEIO_CLIENT_ID']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logger.error("‚ùå Variables d'environnement manquantes:")
            for var in missing_vars:
                logger.error(f"  - {var}")
            return False
        
        # Cr√©er et d√©marrer le pont
        bridge = LucidLinkFrameIOBridge(config)
        
        # Gestion des signaux pour arr√™t propre
        import signal
        
        def signal_handler(signum, frame):
            logger.info(f"üõë Signal {signum} re√ßu, arr√™t du pont...")
            asyncio.create_task(bridge.stop_bridge())
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # D√©marrer le pont
        await bridge.start_bridge()
        
        # Boucle principale avec monitoring
        while bridge.running:
            try:
                await asyncio.sleep(60)  # V√©rifier toutes les minutes
                
                # Afficher les statistiques
                status = await bridge.get_status()
                logger.info(f"üìä Statut: {status['stats']['files_uploaded']} upload√©s, "
                           f"{status['queue_size']} en attente")
                
            except KeyboardInterrupt:
                logger.info("üõë Interruption clavier d√©tect√©e")
                break
            except Exception as e:
                logger.error(f"‚ùå Erreur boucle principale: {e}")
                await asyncio.sleep(10)
        
        # Arr√™t propre
        await bridge.stop_bridge()
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        return False

if __name__ == "__main__":
    # V√©rifier Python 3.8+
    if sys.version_info < (3, 8):
        print("‚ùå Python 3.8+ requis")
        sys.exit(1)
    
    # Lancer le pont
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
